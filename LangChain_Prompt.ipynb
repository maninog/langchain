{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "s_hCfuDIhbI8"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maninog/langchain/blob/main/LangChain_Prompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Prompt"
      ],
      "metadata": {
        "id": "ulRQ6MLpRL1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## README\n",
        "- author: [Masumi Morishige](https://twitter.com/masumi_creator)\n",
        "- created_at: 2023-05-02\n",
        "- updated_at: 2023-05-06\n",
        "\n",
        "### 実行方法\n",
        "1. OpenAIのAPIキーを発行\n",
        "2. `os.environ[\"OPENAI_API_KEY\"] = \"...\"`の`\"\"`の中にご自身のAPIキーを代入\n",
        "3. 「ランタイム > すべてのセルを実行」を実行\n",
        "\n",
        "### 参考情報\n",
        "- Zenn: [LangChain Promptとは？【Templates・Example Selectors・Output Parsers】](https://zenn.dev/umi_mori/books/prompt-engineer/viewer/langchain_prompt)\n",
        "- YouTube: [LangChain Promptとは？【Templates / Example Selectors / Output Parsers】](https://youtu.be/N7IKDNCcUYA)"
      ],
      "metadata": {
        "id": "LGsXSj2f-Dq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI APIの発行方法"
      ],
      "metadata": {
        "id": "s_hCfuDIhbI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[<img src=\"https://img.youtube.com/vi/frpsKLNW1q4/maxresdefault.jpg\" width=\"600px\">](https://youtu.be/frpsKLNW1q4)\n",
        "\n",
        "[【エンジニア向け】OpenAIのAPI連携方法【環境構築 + GASによるGoogle Documentへの組み込み】](https://youtu.be/frpsKLNW1q4)"
      ],
      "metadata": {
        "id": "foH_Uay1iKDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 環境構築"
      ],
      "metadata": {
        "id": "umvezGLzQ5-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install langchain openai"
      ],
      "metadata": {
        "id": "YZwA51jTQNqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCzmvPurP9OP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "#TODO: APIキーの登録が必要\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"...\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Prompt Templateの使い方"
      ],
      "metadata": {
        "id": "tXfl6kiwQ9r8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "template = \"\"\"\n",
        "{subject}について30文字で教えて。\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"subject\"],\n",
        "    template=template,\n",
        ")\n",
        "prompt_text = prompt.format(subject=\"ITエンジニア\")\n",
        "print(prompt_text)\n",
        "\n",
        "llm = OpenAI(model_name=\"text-davinci-003\")\n",
        "print(llm(prompt_text))"
      ],
      "metadata": {
        "id": "T1FOOtXDQJCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain import FewShotPromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "examples = [\n",
        "    {\"fruit\": \"りんご\", \"color\": \"赤\"},\n",
        "    {\"fruit\": \"キウイ\", \"color\": \"緑\"},\n",
        "    {\"fruit\": \"ぶどう\", \"color\": \"紫\"},\n",
        "]\n",
        "\n",
        "example_formatter_template = \"\"\"\n",
        "フルーツ: {fruit}\n",
        "色: {color}\\n\n",
        "\"\"\"\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"fruit\", \"color\"],\n",
        "    template=example_formatter_template,\n",
        ")\n",
        "\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"フルーツの色を漢字で教えて。\",\n",
        "    suffix=\"フルーツ: {input}\\n色:\",\n",
        "    input_variables=[\"input\"],\n",
        "    example_separator=\"\\n\\n\",\n",
        "\n",
        ")\n",
        "\n",
        "prompt_text = few_shot_prompt.format(input=\"オレンジ\")\n",
        "print(prompt_text)\n",
        "\n",
        "llm = OpenAI(model_name=\"text-davinci-003\")\n",
        "print(llm(prompt_text))"
      ],
      "metadata": {
        "id": "U26b8NczWPDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "system_template=\"あなたは、質問者からの質問を{language}で回答するAIです。\"\n",
        "human_template=\"質問者：{question}\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "prompt_message_list = chat_prompt.format_prompt(language=\"日本語\", question=\"ITエンジニアについて30文字で教えて。\").to_messages()\n",
        "\n",
        "print(prompt_message_list)\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
        "chat(prompt_message_list)"
      ],
      "metadata": {
        "id": "_LoM5hpZYao3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import load_prompt\n",
        "\n",
        "prompt = load_prompt(\"lc://prompts/conversation/prompt.json\")\n",
        "prompt_text = prompt.format(history=\"こんにちは、ますみです。\", input=\"ITエンジニアについて30文字で教えて。\")\n",
        "print(prompt_text)"
      ],
      "metadata": {
        "id": "4CRLNXDjVZuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Example Selectorsの使い方"
      ],
      "metadata": {
        "id": "6IL5HMfJRAl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
        "from typing import Dict, List\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CustomExampleSelector(BaseExampleSelector):\n",
        "\n",
        "    def __init__(self, examples: List[Dict[str, str]]):\n",
        "        self.examples = examples\n",
        "\n",
        "    def add_example(self, example: Dict[str, str]) -> None:\n",
        "        \"\"\"新しい教師データを格納するめの関数\"\"\"\n",
        "        self.examples.append(example)\n",
        "\n",
        "    def select_examples(self, input_variables: Dict[str, str]) -> List[dict]:\n",
        "        \"\"\"教師データを選択するための関数\"\"\"\n",
        "        return np.random.choice(self.examples, size=2, replace=False)\n",
        "\n",
        "examples = [\n",
        "    {\"fruit\": \"りんご\", \"color\": \"赤\"},\n",
        "    {\"fruit\": \"キウイ\", \"color\": \"緑\"},\n",
        "    {\"fruit\": \"ぶどう\", \"color\": \"紫\"},\n",
        "]\n",
        "\n",
        "# 教師データの登録\n",
        "example_selector = CustomExampleSelector(examples)\n",
        "\n",
        "# 教師データの出力\n",
        "print(example_selector.examples)\n",
        "\n",
        "# 教師データの追加\n",
        "example_selector.add_example({\"fruit\": \"オレンジ\", \"color\": \"橙\"})\n",
        "print(example_selector.examples)\n",
        "\n",
        "# 教師データの選択\n",
        "print(example_selector.select_examples({\"fruit\": \"fruit\"}))"
      ],
      "metadata": {
        "id": "G6ZkY9D9QMdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Output Parsersの使い方"
      ],
      "metadata": {
        "id": "7zTEZAM9REHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "output_parser = CommaSeparatedListOutputParser()\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "prompt = PromptTemplate(\n",
        "    template=\"List five {subject}.\\n{format_instructions}\",\n",
        "    input_variables=[\"subject\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions}\n",
        ")\n",
        "\n",
        "llm = OpenAI(model_name=\"text-davinci-003\")\n",
        "_input = prompt.format(subject=\"Programming Language\")\n",
        "output = llm(_input)\n",
        "output_parser.parse(output)"
      ],
      "metadata": {
        "id": "JbYacbwyQdVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "\n",
        "class Job(BaseModel):\n",
        "    name: str = Field(description=\"Name of the job\")\n",
        "    skill_list: List[str] = Field(description=\"List of skills required for that job\")\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=Job)\n",
        "prompt = PromptTemplate(\n",
        "    template=\"{query}\\n\\n{format_instructions}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        ")\n",
        "_input = prompt.format_prompt(query=\"Tell me the skills required for frontend engineer.\")\n",
        "print(_input)\n",
        "\n",
        "llm = OpenAI(model_name=\"text-davinci-003\")\n",
        "output = llm(_input.to_string())\n",
        "print(output)\n",
        "\n",
        "parser.parse(output)"
      ],
      "metadata": {
        "id": "UURUABRab1ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.output_parsers import (\n",
        "    PydanticOutputParser,\n",
        "    OutputFixingParser,\n",
        ")\n",
        "\n",
        "class Job(BaseModel):\n",
        "    name: str = Field(description=\"Name of the job\")\n",
        "    skill_list: List[str] = Field(description=\"List of skills required for that job\")\n",
        "\n",
        "misformatted = \"{'name': 'Frontend Engineer', 'skill_list': ['HTML', 'CSS', 'JS', 'TS']}\"\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=Job)\n",
        "\n",
        "new_parser = OutputFixingParser.from_llm(parser=parser, llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\"))\n",
        "new_parser.parse(misformatted)"
      ],
      "metadata": {
        "id": "WkXKHXnDb0E8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}