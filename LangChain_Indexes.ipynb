{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WpPcwNhlhQRI"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maninog/langchain/blob/main/LangChain_Indexes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Indexes"
      ],
      "metadata": {
        "id": "ulRQ6MLpRL1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## README\n",
        "- author: [Masumi Morishige](https://twitter.com/masumi_creator)\n",
        "- created_at: 2023-05-02\n",
        "- updated_at: 2023-05-06\n",
        "\n",
        "### 実行方法\n",
        "1. OpenAIのAPIキーを発行\n",
        "2. `os.environ[\"OPENAI_API_KEY\"] = \"...\"`の`\"\"`の中にご自身のAPIキーを代入\n",
        "3. 「ランタイム > すべてのセルを実行」を実行\n",
        "\n",
        "### 参考情報\n",
        "- Zenn: [LangChain Indexesとは？【Document Loaders・Text Splitters・Vectorstores】](https://zenn.dev/umi_mori/books/prompt-engineer/viewer/langchain_indexes)\n",
        "- YouTube: [LangChain Indexesとは？【Document Loaders / Text Splitters / Vectorstores / Retrievers】](https://youtu.be/7tPMqrAoFAQ)"
      ],
      "metadata": {
        "id": "Yt8Q0D3_g8Xv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI APIの発行方法"
      ],
      "metadata": {
        "id": "WpPcwNhlhQRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[<img src=\"https://img.youtube.com/vi/frpsKLNW1q4/maxresdefault.jpg\" width=\"600px\">](https://youtu.be/frpsKLNW1q4)\n",
        "\n",
        "[【エンジニア向け】OpenAIのAPI連携方法【環境構築 + GASによるGoogle Documentへの組み込み】](https://youtu.be/frpsKLNW1q4)"
      ],
      "metadata": {
        "id": "ZzH-tic8hXac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 環境構築"
      ],
      "metadata": {
        "id": "umvezGLzQ5-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai"
      ],
      "metadata": {
        "id": "YZwA51jTQNqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCzmvPurP9OP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "#TODO: APIキーの登録が必要\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"...\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Document Loadersの使い方"
      ],
      "metadata": {
        "id": "tXfl6kiwQ9r8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pypdf tiktoken chromadb"
      ],
      "metadata": {
        "id": "nfcwgprr9G_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "loader = PyPDFLoader(\"https://blog.freelance-jp.org/wp-content/uploads/2023/03/FreelanceSurvey2023.pdf\")\n",
        "pages = loader.load_and_split()\n",
        "print(pages[0])\n",
        "\n",
        "chroma_index = Chroma.from_documents(pages, OpenAIEmbeddings())\n",
        "docs = chroma_index.similarity_search(\"「フリーランスのリモートワークの実態」について教えて。\", k=2)\n",
        "for doc in docs:\n",
        "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content)"
      ],
      "metadata": {
        "id": "T1FOOtXDQJCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Text Splittersの使い方"
      ],
      "metadata": {
        "id": "6IL5HMfJRAl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "long_text = \"\"\"\n",
        "GPT-4は、OpenAIが開発したAI技術であるGPTシリーズの第4世代目のモデルです。\n",
        "\n",
        "自然言語処理(NLP)という技術を使い、文章の生成や理解を行うことができます。\n",
        "\n",
        "これにより、人間と同じような文章を作成することが可能です。\n",
        "\n",
        "GPT-4は、トランスフォーマーアーキテクチャに基づいており、より強力な性能を発揮します。\n",
        "\n",
        "GPT-4は、インターネット上の大量のテキストデータを学習し、豊富な知識を持っています。\n",
        "\n",
        "しかし、2021年9月までの情報しか持っていません。\n",
        "\n",
        "このモデルは、質問応答や文章生成、文章要約など、様々なタスクで使用できます。\n",
        "\n",
        "ただし、GPT-4は完璧ではありません。\n",
        "\n",
        "時々、誤った情報や不適切な内容を生成することがあります。\n",
        "\n",
        "使用者は、その限界を理解し、\n",
        "\n",
        "適切な方法で利用することが重要です。\n",
        "\"\"\"\n",
        "print(len(long_text))\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\\n\",\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap = 0,\n",
        "    length_function = len,\n",
        ")\n",
        "text_list = text_splitter.split_text(long_text)\n",
        "print(text_list)\n",
        "print(len(text_list))\n",
        "\n",
        "document_list = text_splitter.create_documents([long_text])\n",
        "print(document_list)\n",
        "print(len(document_list))"
      ],
      "metadata": {
        "id": "G6ZkY9D9QMdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(\"GPT-4は、OpenAIが開発したAI技術であるGPTシリーズの第4世代目のモデルです。\\n\\n自然言語処理(NLP)という技術を使い、文章の生成や理解を行うことができます。\")"
      ],
      "metadata": {
        "id": "oobP_wXWvEOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Vectorstoresの使い方"
      ],
      "metadata": {
        "id": "7zTEZAM9REHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "long_text = \"\"\"\n",
        "GPT-4は、OpenAIが開発したAI技術であるGPTシリーズの第4世代目のモデルです。\n",
        "\n",
        "自然言語処理(NLP)という技術を使い、文章の生成や理解を行うことができます。\n",
        "\n",
        "これにより、人間と同じような文章を作成することが可能です。\n",
        "\n",
        "GPT-4は、トランスフォーマーアーキテクチャに基づいており、より強力な性能を発揮します。\n",
        "\n",
        "GPT-4は、インターネット上の大量のテキストデータを学習し、豊富な知識を持っています。\n",
        "\n",
        "しかし、2021年9月までの情報しか持っていません。\n",
        "\n",
        "このモデルは、質問応答や文章生成、文章要約など、様々なタスクで使用できます。\n",
        "\n",
        "ただし、GPT-4は完璧ではありません。\n",
        "\n",
        "時々、誤った情報や不適切な内容を生成することがあります。\n",
        "\n",
        "使用者は、その限界を理解し、\n",
        "\n",
        "適切な方法で利用することが重要です。\n",
        "\"\"\"\n",
        "print(len(long_text))\n",
        "with open(\"./long_text.txt\", \"w\") as f:\n",
        "    f.write(long_text)\n",
        "    f.close()\n",
        "\n",
        "loader = TextLoader('./long_text.txt')\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\\n\",\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap = 0,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "index = VectorstoreIndexCreator(\n",
        "    vectorstore_cls=Chroma, # Default\n",
        "    embedding=OpenAIEmbeddings(), # Default\n",
        "    text_splitter=text_splitter,\n",
        ").from_loaders([loader])\n",
        "\n",
        "query = \"Q1. インターネット上の何のデータを使って、学習しているの？\"\n",
        "print(f\"\\n\\n{query}\")\n",
        "answer = index.query(query)\n",
        "print(answer)\n",
        "\n",
        "answer_with_sources = index.query_with_sources(query)\n",
        "print(answer_with_sources)\n",
        "\n",
        "query = \"Q2. GPT4は第何世代のモデル？\"\n",
        "print(f\"\\n\\n{query}\")\n",
        "answer = index.query(query)\n",
        "print(answer)\n",
        "\n",
        "answer_with_sources = index.query_with_sources(query)\n",
        "print(answer_with_sources)\n"
      ],
      "metadata": {
        "id": "zdStHV-q3U_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "long_text = \"\"\"\n",
        "GPT-4は、OpenAIが開発したAI技術であるGPTシリーズの第4世代目のモデルです。\n",
        "\n",
        "自然言語処理(NLP)という技術を使い、文章の生成や理解を行うことができます。\n",
        "\n",
        "これにより、人間と同じような文章を作成することが可能です。\n",
        "\n",
        "GPT-4は、トランスフォーマーアーキテクチャに基づいており、より強力な性能を発揮します。\n",
        "\n",
        "GPT-4は、インターネット上の大量のテキストデータを学習し、豊富な知識を持っています。\n",
        "\n",
        "しかし、2021年9月までの情報しか持っていません。\n",
        "\n",
        "このモデルは、質問応答や文章生成、文章要約など、様々なタスクで使用できます。\n",
        "\n",
        "ただし、GPT-4は完璧ではありません。\n",
        "\n",
        "時々、誤った情報や不適切な内容を生成することがあります。\n",
        "\n",
        "使用者は、その限界を理解し、\n",
        "\n",
        "適切な方法で利用することが重要です。\n",
        "\"\"\"\n",
        "print(len(long_text))\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\\n\",\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap = 0,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "texts = text_splitter.split_text(long_text)\n",
        "\n",
        "docsearch = Chroma.from_texts(texts, OpenAIEmbeddings())\n",
        "\n",
        "query = \"Q1. インターネット上の何のデータを使って、学習しているの？\"\n",
        "print(f\"\\n\\n{query}\")\n",
        "docs = docsearch.similarity_search(query)\n",
        "print(docs[0].page_content)\n",
        "\n",
        "query = \"Q2. GPT4は第何世代のモデルは？\"\n",
        "print(f\"\\n\\n{query}\")\n",
        "docs = docsearch.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "id": "JbYacbwyQdVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Retrieversの使い方"
      ],
      "metadata": {
        "id": "cjNkjs5162Ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "long_text = \"\"\"\n",
        "GPT-4は、OpenAIが開発したAI技術であるGPTシリーズの第4世代目のモデルです。\n",
        "\n",
        "自然言語処理(NLP)という技術を使い、文章の生成や理解を行うことができます。\n",
        "\n",
        "これにより、人間と同じような文章を作成することが可能です。\n",
        "\n",
        "GPT-4は、トランスフォーマーアーキテクチャに基づいており、より強力な性能を発揮します。\n",
        "\n",
        "GPT-4は、インターネット上の大量のテキストデータを学習し、豊富な知識を持っています。\n",
        "\n",
        "しかし、2021年9月までの情報しか持っていません。\n",
        "\n",
        "このモデルは、質問応答や文章生成、文章要約など、様々なタスクで使用できます。\n",
        "\n",
        "ただし、GPT-4は完璧ではありません。\n",
        "\n",
        "時々、誤った情報や不適切な内容を生成することがあります。\n",
        "\n",
        "使用者は、その限界を理解し、\n",
        "\n",
        "適切な方法で利用することが重要です。\n",
        "\"\"\"\n",
        "print(len(long_text))\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\\n\",\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap = 0,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "document_list = text_splitter.create_documents([long_text])\n",
        "print(document_list)\n",
        "print(len(document_list))\n",
        "\n",
        "db = FAISS.from_documents(document_list, OpenAIEmbeddings())\n",
        "retriever = db.as_retriever()\n",
        "\n",
        "query = \"Q1. インターネット上の何のデータを使って、学習しているの？\"\n",
        "print(f\"\\n\\n{query}\")\n",
        "docs = retriever.get_relevant_documents(query)\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "id": "UURUABRab1ry"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}